{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "- Target class has 2 values -> 0 or 1\n",
    "\n",
    "    -> 0 refers to edible\n",
    "    \n",
    "    -> 1 refers to poisonous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
      "0              1372          2                2          10     3.807467   \n",
      "1              1461          2                2          10     3.807467   \n",
      "2              1371          2                2          10     3.612496   \n",
      "3              1261          6                2          10     3.787572   \n",
      "4              1305          6                2          10     3.711971   \n",
      "...             ...        ...              ...         ...          ...   \n",
      "54030            73          5                3           2     0.887740   \n",
      "54031            82          2                3           2     1.186164   \n",
      "54032            82          5                3           2     0.915593   \n",
      "54033            79          2                3           2     1.034963   \n",
      "54034            72          5                3           2     1.158311   \n",
      "\n",
      "       stem-width  stem-color    season  class  \n",
      "0            1545          11  1.804273      1  \n",
      "1            1557          11  1.804273      1  \n",
      "2            1566          11  1.804273      1  \n",
      "3            1566          11  1.804273      1  \n",
      "4            1464          11  0.943195      1  \n",
      "...           ...         ...       ...    ...  \n",
      "54030         569          12  0.943195      1  \n",
      "54031         490          12  0.943195      1  \n",
      "54032         584          12  0.888450      1  \n",
      "54033         491          12  0.888450      1  \n",
      "54034         492          12  0.888450      1  \n",
      "\n",
      "[54035 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/mushroom_cleaned.csv\")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.612496</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.787572</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.711971</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       "0          1372          2                2          10     3.807467   \n",
       "1          1461          2                2          10     3.807467   \n",
       "2          1371          2                2          10     3.612496   \n",
       "3          1261          6                2          10     3.787572   \n",
       "4          1305          6                2          10     3.711971   \n",
       "\n",
       "   stem-width  stem-color    season  class  \n",
       "0        1545          11  1.804273      1  \n",
       "1        1557          11  1.804273      1  \n",
       "2        1566          11  1.804273      1  \n",
       "3        1566          11  1.804273      1  \n",
       "4        1464          11  0.943195      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54035 entries, 0 to 54034\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   cap-diameter     54035 non-null  int64  \n",
      " 1   cap-shape        54035 non-null  int64  \n",
      " 2   gill-attachment  54035 non-null  int64  \n",
      " 3   gill-color       54035 non-null  int64  \n",
      " 4   stem-height      54035 non-null  float64\n",
      " 5   stem-width       54035 non-null  int64  \n",
      " 6   stem-color       54035 non-null  int64  \n",
      " 7   season           54035 non-null  float64\n",
      " 8   class            54035 non-null  int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to count the number of positives and negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1    29675\n",
       "0    24360\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realization: data skew is heavy towards poisonous so this will affect model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1372</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1545</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.807467</td>\n",
       "      <td>1557</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1371</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.612496</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1261</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.787572</td>\n",
       "      <td>1566</td>\n",
       "      <td>11</td>\n",
       "      <td>1.804273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.711971</td>\n",
       "      <td>1464</td>\n",
       "      <td>11</td>\n",
       "      <td>0.943195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54030</th>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.887740</td>\n",
       "      <td>569</td>\n",
       "      <td>12</td>\n",
       "      <td>0.943195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54031</th>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.186164</td>\n",
       "      <td>490</td>\n",
       "      <td>12</td>\n",
       "      <td>0.943195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54032</th>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.915593</td>\n",
       "      <td>584</td>\n",
       "      <td>12</td>\n",
       "      <td>0.888450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54033</th>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.034963</td>\n",
       "      <td>491</td>\n",
       "      <td>12</td>\n",
       "      <td>0.888450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54034</th>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.158311</td>\n",
       "      <td>492</td>\n",
       "      <td>12</td>\n",
       "      <td>0.888450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54035 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cap-diameter  cap-shape  gill-attachment  gill-color  stem-height  \\\n",
       "0              1372          2                2          10     3.807467   \n",
       "1              1461          2                2          10     3.807467   \n",
       "2              1371          2                2          10     3.612496   \n",
       "3              1261          6                2          10     3.787572   \n",
       "4              1305          6                2          10     3.711971   \n",
       "...             ...        ...              ...         ...          ...   \n",
       "54030            73          5                3           2     0.887740   \n",
       "54031            82          2                3           2     1.186164   \n",
       "54032            82          5                3           2     0.915593   \n",
       "54033            79          2                3           2     1.034963   \n",
       "54034            72          5                3           2     1.158311   \n",
       "\n",
       "       stem-width  stem-color    season  \n",
       "0            1545          11  1.804273  \n",
       "1            1557          11  1.804273  \n",
       "2            1566          11  1.804273  \n",
       "3            1566          11  1.804273  \n",
       "4            1464          11  0.943195  \n",
       "...           ...         ...       ...  \n",
       "54030         569          12  0.943195  \n",
       "54031         490          12  0.943195  \n",
       "54032         584          12  0.888450  \n",
       "54033         491          12  0.888450  \n",
       "54034         492          12  0.888450  \n",
       "\n",
       "[54035 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "54030    1\n",
       "54031    1\n",
       "54032    1\n",
       "54033    1\n",
       "54034    1\n",
       "Name: class, Length: 54035, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into testing and training data such that we have 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2\n",
    "                                                    , random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float128'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_train, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat128\u001b[49m)\n\u001b[0;32m      2\u001b[0m X_train\n",
      "File \u001b[1;32mc:\\Users\\zayaa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\__init__.py:347\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRemoved in NumPy 1.25.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTester was removed in NumPy 1.25.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 347\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    348\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float128'"
     ]
    }
   ],
   "source": [
    "X_train = np.array(X_train, dtype=np.float128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train, dtype=np.float128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We make our own Logistic Regression model from scratch instead of using pre-built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel():\n",
    "    def __init__(self, learning_rate, num_iters):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iters = num_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # need to map N_SAMPLES to the rows and N_FEATURES to the cols\n",
    "        n_samples, n_features = np.shape(X)\n",
    "        # originally intiialize Wn to be 0 for each feature\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.num_iters):\n",
    "            # calculate our linear predictions (z = wx + b) to be passed into sigmoid\n",
    "            linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "            # calculate our actual predictions (f_wb) using sigmoid for linear_predicts\n",
    "            predictions = self.sigmoid(linear_predictions)\n",
    "\n",
    "            # calculting the gradients for w and b\n",
    "            dw = (1 / 2 * n_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / 2 * n_samples) * np.sum(predictions - y)\n",
    "\n",
    "            # updating w and b\n",
    "            # w = w - alpha * dw, b = b - alpha * db\n",
    "            self.weights = self.weights - self.learning_rate * dw\n",
    "            self.bias = self.bias - self.learning_rate * db\n",
    "\n",
    "    def predict_probabilites(self, X):\n",
    "        linear_preds = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted_probabilites = self.sigmoid(linear_preds)\n",
    "        return np.array(y_predicted_probabilites)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # same code as above\n",
    "        linear_predictions = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self.sigmoid(linear_predictions)\n",
    "\n",
    "        class_prediction = []\n",
    "        # threshold\n",
    "        for _ in range(len(y_pred)):\n",
    "            if y_pred[_] < 0.5: class_prediction.append(0)\n",
    "            if y_pred[_] >= 0.5: class_prediction.append(1)\n",
    "        return class_prediction\n",
    "    \n",
    "    def get_accuracy(self, y_predictions, y_test):\n",
    "        return np.sum(y_predictions == y_test) /  len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegressionModel(learning_rate=0.01, num_iters=1000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_predictions)\n",
    "print()\n",
    "\n",
    "y_predictions = np.array(y_predictions)\n",
    "\n",
    "y_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edible_count = 0\n",
    "poisonous_count = 0\n",
    "\n",
    "for i in range(len(y_predictions)):\n",
    "    if y_predictions[i] == 0:\n",
    "        edible_count += 1\n",
    "    else:\n",
    "        poisonous_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Edible:\", edible_count)\n",
    "print(\"Poisonous:\", poisonous_count) # skew is heavy towards poisonous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_predictions)\n",
    "\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_predictions)\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we can see based on the accuracy of 53% that logistic regression may not be the best fit for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "labels = ['Edible', 'Poisonous']\n",
    "\n",
    "display_confusion_matrix = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=labels)\n",
    "display_confusion_matrix.plot(cmap=\"Blues\", ax=ax)\n",
    "\n",
    "ax.set_xticklabels([\"Predicted: Edible\", \"Predicted: Poisonous\"])\n",
    "ax.set_yticklabels([\"Actual: Edible\", \"Actual: Poisonous\"])\n",
    "\n",
    "# Adjusting the confusion matrix annotations for TP, FN, FP, TN\n",
    "ax.texts[0].set_text(f'TN: {confusion_matrix[0, 0]}')\n",
    "ax.texts[1].set_text(f'FP: {confusion_matrix[0, 1]}')\n",
    "ax.texts[2].set_text(f'FN: {confusion_matrix[1, 0]}')\n",
    "ax.texts[3].set_text(f'TP: {confusion_matrix[1, 1]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the built in LogisticRegression model we get a different accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, penalty=None)\n",
    "model.fit(X_train, y_train)\n",
    "print(model.coef_)\n",
    "\n",
    "model_predicts = model.predict(X_train)\n",
    "\n",
    "pre_built_acc = accuracy_score(y_train, model_predicts)\n",
    "print(\"Accuracy of prebuilt:\", pre_built_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
